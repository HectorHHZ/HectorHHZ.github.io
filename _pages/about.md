---
permalink: /
title: "BIO"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a third-year PhD student in the School of Computer Science at Carnegie Mellon University(CMU), specializing in machine learning and computer software engineering. My research focuses on **Large Language Model post-training**, make the LLMs **better** (more align with domain specific tasks), **faster** (more efficient in training and inference), and **cheaper** (training with less GPU hours and GPU memory utilization).

At CMU, I am advised by Prof. [Heather Miller](https://heather.miller.am/). Previously, I earned my master in Computer Science from New York University advised by Prof. [Anna Choromanska](https://engineering.nyu.edu/faculty/anna-choromanska) and Prof. [Parijat Dube](https://scholar.google.com/citations?user=bOejjQUAAAAJ&hl=en). I received my B.S. in Computer Science and Engineering from The Chinese University of Hong Kong(CUHK) where I worked with Prof. [David Zhang, Dapeng](https://scholar.google.com/citations?hl=zh-CN&user=IOagLnEAAAAJ) and [Prof. Rui Huang](https://scholar.google.com/citations?user=t8UduWwAAAAJ&hl=zh-CN&oi=ao). Before starting my PhD, My research mainly focuses on distributed machine learning system. 

- (This personal website is updated as of March 2025.)




## News
- 5-2025:  I will intern at AWS-AI-Labs@Amazon this summer working on LLM post-training enabled speculative decoding via latent space reasoning.
- 2-2025: Open-source [SMT](https://github.com/HectorHHZ/Sparse_Matrix_Tuning?tab=readme-ov-file). We implemented SMT in two frameworks: DeepSpeed and Hugging Face Trainer.
- 2-2025: [SMT: Fine-Tuning Large Language Models with Sparse Matrices](https://openreview.net/forum?id=GbgCRJedQ7), has been accepted by ICLR 2025.
- 5-2024: [Adjacent Leader Decentralized Stochastic Gradient Descent](https://ebooks.iospress.nl/volumearticle/69872) has been accepted by ECAI 2024.
- 4-2024: [Multi-View Radar Autoencoder for Self-Supervised Automotive Radar Representation Learning](https://ieeexplore.ieee.org/abstract/document/10588463) has been accepted by IEEE Intelligent Vehicles Symposium (IV) 2024.
- I started my Ph.D. journey at CMU.
- 2- 2023: Open-source a  general [codebase](https://github.com/HectorHHZ/Adjacent_Leader_Dencentralized_SGD) to implement any (de)centralized, (a)synchronous distributed SGD algorithms when models fit into a single machine. The paper, which proposes a novel distributed SGD algorithm. 




## Selected Publications
<!-- - **Haoze He**, Xingyuan Ding, Xuan Jiang, Alex Cheng, Yibo Zhao, Juncheng Billy Li, Heather Miller, "*Fine-Tuning MoE Large Language Models with Condenser Experts*", *International Conference on Learning Representations (ICLR)*, Submitted, Sept. 2025. [[paper]] -->

- **Haoze He**, Juncheng Billy Li, Xuan Jiang, Heather Miller, "*[Sparse Matrix in Large Language Model Fine-Tuning](https://openreview.net/forum?id=GbgCRJedQ7)*", *International Conference on Learning Representations (ICLR)*, Accepted, Jan. 2025. [[code](https://github.com/HectorHHZ/Sparse_Matrix_Tuning/)]

- **Haoze He**, Jing Wang, Anna Choromanska, "*[Adjacent Leader Decentralized Stochastic Gradient Descent](https://ebooks.iospress.nl/volumearticle/69872)*", *European Conference on Artificial Intelligence (ECAI)*, Accepted, June 2024. [[code](https://github.com/HectorHHZ/Adjacent_Leader_Dencentralized_SGD)]


*My full publication list can be found on my [Google Scholar profile](https://scholar.google.com/citations?user=PKGTBOcAAAAJ&hl=en&oi=ao).*



<br>

## Academic Blog
- Peter Zhong, **Haoze He**, Omar Khattab, Christopher Potts, Matei Zaharia, Heather Miller, "*[A Guide to Large Language Model Abstractions](https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/)*", Jan. 2024.



## Education
- Ph.D. in Machine Learning and Software Engineering at Carnegie Mellon University, 2023-present
  - GPA: 4.16/4.0, Rank: top1%
- M.S. in Computer Engineering at New York University, 2021-2023
  - GPA: 3.93/4.0, Rank: top1%
- B.S. in Computer Science and Engineering at The Chinese University of Hong Kong, 2016-2020




<div class="collapsible-section">
<h2 class="collapsible-header">Work Experience</h2>
<div class="collapsible-content">
<ul>
<li><strong>Applied Research Scientist Intern</strong>, <em>Amazon AWS AI Labs</em>, Summer 2025</li>
</ul>
<ul>
<li><strong>Teaching Assistant</strong>, <em>Carnegie Mellon University, LTI at SCS, Large Language Model Systems (11-868)</em>, Spring 2025</li>
</ul>
<ul>
<li><strong>Research Assistant</strong>, <em>Carnegie Mellon University, S3D at SCS</em>, 2023 ~ present</li>
</ul>
<ul>
<li><strong>Research Assistant</strong>, <em>New York University, Engineering School</em>, 2022 ~ 2023</li>
</ul>
</div>
</div>

<div class="collapsible-section">
<h2 class="collapsible-header collapsed">Awards</h2>
<div class="collapsible-content collapsed">
<ul>
<li><strong>Presidential Fellowship</strong>, <em>Carnegie Mellon University</em>, Nov. 2024</li>
</ul>
</div>
</div>

<!-- <div class="collapsible-section">
<h2 class="collapsible-header collapsed">Teaching</h2>
<div class="collapsible-content collapsed">
<ul>
<li><strong>Teaching Assistant</strong>, <em>Large Language Model Systems (CMU 11-868)</em>, Spring 2025</li>
</ul>
</div>
</div> -->

<div class="collapsible-section">
<h2 class="collapsible-header">Service</h2>
<div class="collapsible-content">
<ul>
<li><strong>Reviewer</strong>, <em>International Conference on Learning Representations (ICLR)</em> — 2025, 2026</li>
<li><strong>Reviewer</strong>, <em>International Joint Conference on Neural Networks (IJCNN)</em> — 2025</li>
<li><strong>Reviewer</strong>, <em>The Association for the Advancement of Artificial Intelligence (AAAI)</em> — 2025</li>
<li><strong>Reviewer</strong>, <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> — 2022 – 2025</li>
<li><strong>Reviewer</strong>, <em>International Conference on Computer Vision (ICCV) Workshops</em> — 2023</li>
</ul>
</div>
</div>

<div class="collapsible-section">
<!-- <h2 class="collapsible-header">Open-Sources for the Community</h2>
<div class="collapsible-content"> -->
<h2 class="collapsible-header collapsed">Open-Sources for the Community</h2>
<div class="collapsible-content collapsed">
<ul>
<li>Build an <strong>open-source <a href="https://github.com/HectorHHZ/NYU-Course-Schedule">website</a></strong> for NYU EECS/DS community and help <strong>150+</strong> NYU students <strong>each semester</strong>. This website summary the open-source courses in NYU EECS/DS, provide links and repositories for each course, list the workload, and provide course experiences for reference. Anyone from the NYU community is welcome to fork and contribute!</li>
</ul>
</div>
</div>
